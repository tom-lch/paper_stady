{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用基于 tensorflow的keras 的 Sequential 顺序模型来实现yolo v2\n",
    "from tensorflow.keras import Sequential, Input\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, GlobalAveragePooling2D, Softmax, Flatten, BatchNormalization, LeakyReLU\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化Sequential模型\n",
    "model = Sequential()\n",
    "# 第一层 卷积层 Convolutional 卷积核 3*3 步长 1 filters 32 outpot 224*224\n",
    "model.add(Conv2D(\n",
    "    filters=32,\n",
    "    kernel_size=(3, 3),\n",
    "    strides=(1, 1),\n",
    "    padding='same',\n",
    "    data_format=None,\n",
    "    dilation_rate=(1, 1),\n",
    "    activation=None,\n",
    "    use_bias=True,\n",
    "    kernel_initializer='glorot_uniform',\n",
    "    bias_initializer='zeros',\n",
    "    kernel_regularizer=l2(0.0005),\n",
    "    bias_regularizer=None,\n",
    "    activity_regularizer=None,\n",
    "    kernel_constraint=None,\n",
    "    bias_constraint=None,\n",
    "))\n",
    "# 进行batch normalization\n",
    "model.add(BatchNormalization(\n",
    "    axis=-1,\n",
    "    momentum=0.90,\n",
    "    epsilon=0.001,\n",
    "    center=True,\n",
    "    scale=True,\n",
    "    beta_initializer='zeros',\n",
    "    gamma_initializer='ones',\n",
    "    moving_mean_initializer='zeros',\n",
    "    moving_variance_initializer='ones',\n",
    "    beta_regularizer=None,\n",
    "    gamma_regularizer=None,\n",
    "    beta_constraint=None,\n",
    "    gamma_constraint=None,\n",
    "    renorm=False,\n",
    "    renorm_clipping=None,\n",
    "    renorm_momentum=0.99,\n",
    "    fused=None,\n",
    "    trainable=True,\n",
    "    virtual_batch_size=None,\n",
    "    adjustment=None,\n",
    "    name=None,\n",
    "))\n",
    "model.add(LeakyReLU(\n",
    "    alpha = 0.1\n",
    "))\n",
    "# 第二层 进行最大池化 size=(2, 2) strides = 2 outpot 112*112\n",
    "model.add(MaxPool2D(\n",
    "    pool_size=(2, 2),\n",
    "    strides=2,\n",
    "    padding='same',\n",
    "    data_format=None\n",
    "))\n",
    "#第三层 Convolutional filters=64, size=(3, 3) strides=1, output 112*112\n",
    "model.add(Conv2D(\n",
    "    filters=64,\n",
    "    kernel_size=(3, 3),\n",
    "    strides=(1, 1),\n",
    "    padding='same',\n",
    "    data_format=None,\n",
    "    dilation_rate=(1, 1),\n",
    "    activation=None,\n",
    "    use_bias=True,\n",
    "    kernel_initializer='glorot_uniform',\n",
    "    bias_initializer='zeros',\n",
    "    kernel_regularizer=l2(0.0005),\n",
    "    bias_regularizer=None,\n",
    "    activity_regularizer=None,\n",
    "    kernel_constraint=None,\n",
    "    bias_constraint=None,\n",
    "))\n",
    "# 进行batch normalization\n",
    "model.add(BatchNormalization(\n",
    "    axis=-1,\n",
    "    momentum=0.90,\n",
    "    epsilon=0.001,\n",
    "    center=True,\n",
    "    scale=True,\n",
    "    beta_initializer='zeros',\n",
    "    gamma_initializer='ones',\n",
    "    moving_mean_initializer='zeros',\n",
    "    moving_variance_initializer='ones',\n",
    "    beta_regularizer=None,\n",
    "    gamma_regularizer=None,\n",
    "    beta_constraint=None,\n",
    "    gamma_constraint=None,\n",
    "    renorm=False,\n",
    "    renorm_clipping=None,\n",
    "    renorm_momentum=0.99,\n",
    "    fused=None,\n",
    "    trainable=True,\n",
    "    virtual_batch_size=None,\n",
    "    adjustment=None,\n",
    "    name=None,\n",
    "))\n",
    "model.add(LeakyReLU(\n",
    "    alpha = 0.1\n",
    "))\n",
    "# 第四层 Maxpool size=(2, 2) strides = 2 outpot 56*56\n",
    "model.add(MaxPool2D(\n",
    "    pool_size=(2, 2),\n",
    "    strides=2,\n",
    "    padding='same',\n",
    "    data_format=None\n",
    "))\n",
    "# 第五层 Convolutional filters=128, size=(3, 3) strides=1, output 56*56\n",
    "model.add(Conv2D(\n",
    "    filters=128,\n",
    "    kernel_size=(3, 3),\n",
    "    strides=(1, 1),\n",
    "    padding='same',\n",
    "    data_format=None,\n",
    "    dilation_rate=(1, 1),\n",
    "    activation=None,\n",
    "    use_bias=True,\n",
    "    kernel_initializer='glorot_uniform',\n",
    "    bias_initializer='zeros',\n",
    "    kernel_regularizer=l2(0.0005),\n",
    "    bias_regularizer=None,\n",
    "    activity_regularizer=None,\n",
    "    kernel_constraint=None,\n",
    "    bias_constraint=None,\n",
    "))\n",
    "# 进行batch normalization\n",
    "model.add(BatchNormalization(\n",
    "    axis=-1,\n",
    "    momentum=0.90,\n",
    "    epsilon=0.001,\n",
    "    center=True,\n",
    "    scale=True,\n",
    "    beta_initializer='zeros',\n",
    "    gamma_initializer='ones',\n",
    "    moving_mean_initializer='zeros',\n",
    "    moving_variance_initializer='ones',\n",
    "    beta_regularizer=None,\n",
    "    gamma_regularizer=None,\n",
    "    beta_constraint=None,\n",
    "    gamma_constraint=None,\n",
    "    renorm=False,\n",
    "    renorm_clipping=None,\n",
    "    renorm_momentum=0.99,\n",
    "    fused=None,\n",
    "    trainable=True,\n",
    "    virtual_batch_size=None,\n",
    "    adjustment=None,\n",
    "    name=None,\n",
    "))\n",
    "model.add(LeakyReLU(\n",
    "    alpha = 0.1\n",
    "))\n",
    "# 第六层 Convolutional filter64, size=(1, 1) strides=1, output=56\n",
    "model.add(Conv2D(\n",
    "    filters=64,\n",
    "    kernel_size=(1, 1),\n",
    "    strides=(1, 1),\n",
    "    padding='same',\n",
    "    data_format=None,\n",
    "    dilation_rate=(1, 1),\n",
    "    activation=None,\n",
    "    use_bias=True,\n",
    "    kernel_initializer='glorot_uniform',\n",
    "    bias_initializer='zeros',\n",
    "    kernel_regularizer=l2(0.0005),\n",
    "    bias_regularizer=None,\n",
    "    activity_regularizer=None,\n",
    "    kernel_constraint=None,\n",
    "    bias_constraint=None,\n",
    "))\n",
    "# 进行batch normalization\n",
    "model.add(BatchNormalization(\n",
    "    axis=-1,\n",
    "    momentum=0.90,\n",
    "    epsilon=0.001,\n",
    "    center=True,\n",
    "    scale=True,\n",
    "    beta_initializer='zeros',\n",
    "    gamma_initializer='ones',\n",
    "    moving_mean_initializer='zeros',\n",
    "    moving_variance_initializer='ones',\n",
    "    beta_regularizer=None,\n",
    "    gamma_regularizer=None,\n",
    "    beta_constraint=None,\n",
    "    gamma_constraint=None,\n",
    "    renorm=False,\n",
    "    renorm_clipping=None,\n",
    "    renorm_momentum=0.99,\n",
    "    fused=None,\n",
    "    trainable=True,\n",
    "    virtual_batch_size=None,\n",
    "    adjustment=None,\n",
    "    name=None,\n",
    "))\n",
    "model.add(LeakyReLU(\n",
    "    alpha = 0.1\n",
    "))\n",
    "# 第七层 Convolutional filter 128, size=(3, 3) strides=1, output=56*56\n",
    "model.add(Conv2D(\n",
    "    filters=128,\n",
    "    kernel_size=(3, 3),\n",
    "    strides=(1, 1),\n",
    "    padding='same',\n",
    "    data_format=None,\n",
    "    dilation_rate=(1, 1),\n",
    "    activation=None,\n",
    "    use_bias=True,\n",
    "    kernel_initializer='glorot_uniform',\n",
    "    bias_initializer='zeros',\n",
    "    kernel_regularizer=l2(0.0005),\n",
    "    bias_regularizer=None,\n",
    "    activity_regularizer=None,\n",
    "    kernel_constraint=None,\n",
    "    bias_constraint=None,\n",
    "))\n",
    "# 进行batch normalization\n",
    "model.add(BatchNormalization(\n",
    "    axis=-1,\n",
    "    momentum=0.90,\n",
    "    epsilon=0.001,\n",
    "    center=True,\n",
    "    scale=True,\n",
    "    beta_initializer='zeros',\n",
    "    gamma_initializer='ones',\n",
    "    moving_mean_initializer='zeros',\n",
    "    moving_variance_initializer='ones',\n",
    "    beta_regularizer=None,\n",
    "    gamma_regularizer=None,\n",
    "    beta_constraint=None,\n",
    "    gamma_constraint=None,\n",
    "    renorm=False,\n",
    "    renorm_clipping=None,\n",
    "    renorm_momentum=0.99,\n",
    "    fused=None,\n",
    "    trainable=True,\n",
    "    virtual_batch_size=None,\n",
    "    adjustment=None,\n",
    "    name=None,\n",
    "))\n",
    "model.add(LeakyReLU(\n",
    "    alpha = 0.1\n",
    "))\n",
    "# 第八层 Maxpool size=(2, 2) strides = 2 outpot 28*28\n",
    "model.add(MaxPool2D(\n",
    "    pool_size=(2, 2),\n",
    "    strides=2,\n",
    "    padding='same',\n",
    "    data_format=None\n",
    "))\n",
    "# 第九层 Convolutional filter 256, size=(3, 3) strides=1, output=28*28\n",
    "model.add(Conv2D(\n",
    "    filters=256,\n",
    "    kernel_size=(3, 3),\n",
    "    strides=(1, 1),\n",
    "    padding='same',\n",
    "    data_format=None,\n",
    "    dilation_rate=(1, 1),\n",
    "    activation=None,\n",
    "    use_bias=True,\n",
    "    kernel_initializer='glorot_uniform',\n",
    "    bias_initializer='zeros',\n",
    "    kernel_regularizer=l2(0.0005),\n",
    "    bias_regularizer=None,\n",
    "    activity_regularizer=None,\n",
    "    kernel_constraint=None,\n",
    "    bias_constraint=None,\n",
    "))\n",
    "# 进行batch normalization\n",
    "model.add(BatchNormalization(\n",
    "    axis=-1,\n",
    "    momentum=0.90,\n",
    "    epsilon=0.001,\n",
    "    center=True,\n",
    "    scale=True,\n",
    "    beta_initializer='zeros',\n",
    "    gamma_initializer='ones',\n",
    "    moving_mean_initializer='zeros',\n",
    "    moving_variance_initializer='ones',\n",
    "    beta_regularizer=None,\n",
    "    gamma_regularizer=None,\n",
    "    beta_constraint=None,\n",
    "    gamma_constraint=None,\n",
    "    renorm=False,\n",
    "    renorm_clipping=None,\n",
    "    renorm_momentum=0.99,\n",
    "    fused=None,\n",
    "    trainable=True,\n",
    "    virtual_batch_size=None,\n",
    "    adjustment=None,\n",
    "    name=None,\n",
    "))\n",
    "model.add(LeakyReLU(\n",
    "    alpha = 0.1\n",
    "))\n",
    "# 第十层 Convolutional filter 128 size=(1, 1) strides=1, output=28*28\n",
    "model.add(Conv2D(\n",
    "    filters=128,\n",
    "    kernel_size=(1, 1),\n",
    "    strides=(1, 1),\n",
    "    padding='same',\n",
    "    data_format=None,\n",
    "    dilation_rate=(1, 1),\n",
    "    activation=None,\n",
    "    use_bias=True,\n",
    "    kernel_initializer='glorot_uniform',\n",
    "    bias_initializer='zeros',\n",
    "    kernel_regularizer=l2(0.0005),\n",
    "    bias_regularizer=None,\n",
    "    activity_regularizer=None,\n",
    "    kernel_constraint=None,\n",
    "    bias_constraint=None,\n",
    "))\n",
    "# 进行batch normalization\n",
    "model.add(BatchNormalization(\n",
    "    axis=-1,\n",
    "    momentum=0.90,\n",
    "    epsilon=0.001,\n",
    "    center=True,\n",
    "    scale=True,\n",
    "    beta_initializer='zeros',\n",
    "    gamma_initializer='ones',\n",
    "    moving_mean_initializer='zeros',\n",
    "    moving_variance_initializer='ones',\n",
    "    beta_regularizer=None,\n",
    "    gamma_regularizer=None,\n",
    "    beta_constraint=None,\n",
    "    gamma_constraint=None,\n",
    "    renorm=False,\n",
    "    renorm_clipping=None,\n",
    "    renorm_momentum=0.99,\n",
    "    fused=None,\n",
    "    trainable=True,\n",
    "    virtual_batch_size=None,\n",
    "    adjustment=None,\n",
    "    name=None,\n",
    "))\n",
    "model.add(LeakyReLU(\n",
    "    alpha = 0.1\n",
    "))\n",
    "# 第十一层 Convolutional filter 256 size=(3, 3) strides=1, output=28*28\n",
    "model.add(Conv2D(\n",
    "    filters=256,\n",
    "    kernel_size=(3, 3),\n",
    "    strides=(1, 1),\n",
    "    padding='same',\n",
    "    data_format=None,\n",
    "    dilation_rate=(1, 1),\n",
    "    activation=None,\n",
    "    use_bias=True,\n",
    "    kernel_initializer='glorot_uniform',\n",
    "    bias_initializer='zeros',\n",
    "    kernel_regularizer=l2(0.0005),\n",
    "    bias_regularizer=None,\n",
    "    activity_regularizer=None,\n",
    "    kernel_constraint=None,\n",
    "    bias_constraint=None,\n",
    "))\n",
    "# 进行batch normalization\n",
    "model.add(BatchNormalization(\n",
    "    axis=-1,\n",
    "    momentum=0.90,\n",
    "    epsilon=0.001,\n",
    "    center=True,\n",
    "    scale=True,\n",
    "    beta_initializer='zeros',\n",
    "    gamma_initializer='ones',\n",
    "    moving_mean_initializer='zeros',\n",
    "    moving_variance_initializer='ones',\n",
    "    beta_regularizer=None,\n",
    "    gamma_regularizer=None,\n",
    "    beta_constraint=None,\n",
    "    gamma_constraint=None,\n",
    "    renorm=False,\n",
    "    renorm_clipping=None,\n",
    "    renorm_momentum=0.99,\n",
    "    fused=None,\n",
    "    trainable=True,\n",
    "    virtual_batch_size=None,\n",
    "    adjustment=None,\n",
    "    name=None,\n",
    "))\n",
    "model.add(LeakyReLU(\n",
    "    alpha = 0.1\n",
    "))\n",
    "# 第十二层 Maxpool size=(2, 2) strides = 2 outpot 14*14\n",
    "model.add(MaxPool2D(\n",
    "    pool_size=(2, 2),\n",
    "    strides=2,\n",
    "    padding='same',\n",
    "    data_format=None\n",
    "))\n",
    "# 第十三层 Convolutional filter 512 size=(3, 3) strides=1, output=14*14\n",
    "model.add(Conv2D(\n",
    "    filters=512,\n",
    "    kernel_size=(3, 3),\n",
    "    strides=(1, 1),\n",
    "    padding='same',\n",
    "    data_format=None,\n",
    "    dilation_rate=(1, 1),\n",
    "    activation=None,\n",
    "    use_bias=True,\n",
    "    kernel_initializer='glorot_uniform',\n",
    "    bias_initializer='zeros',\n",
    "    kernel_regularizer=l2(0.0005),\n",
    "    bias_regularizer=None,\n",
    "    activity_regularizer=None,\n",
    "    kernel_constraint=None,\n",
    "    bias_constraint=None,\n",
    "))\n",
    "# 进行batch normalization\n",
    "model.add(BatchNormalization(\n",
    "    axis=-1,\n",
    "    momentum=0.90,\n",
    "    epsilon=0.001,\n",
    "    center=True,\n",
    "    scale=True,\n",
    "    beta_initializer='zeros',\n",
    "    gamma_initializer='ones',\n",
    "    moving_mean_initializer='zeros',\n",
    "    moving_variance_initializer='ones',\n",
    "    beta_regularizer=None,\n",
    "    gamma_regularizer=None,\n",
    "    beta_constraint=None,\n",
    "    gamma_constraint=None,\n",
    "    renorm=False,\n",
    "    renorm_clipping=None,\n",
    "    renorm_momentum=0.99,\n",
    "    fused=None,\n",
    "    trainable=True,\n",
    "    virtual_batch_size=None,\n",
    "    adjustment=None,\n",
    "    name=None,\n",
    "))\n",
    "model.add(LeakyReLU(\n",
    "    alpha = 0.1\n",
    "))\n",
    "# 第十四层 Convolutional filter 256 size=(1, 1) strides=1, output=14*14\n",
    "model.add(Conv2D(\n",
    "    filters=256,\n",
    "    kernel_size=(1, 1),\n",
    "    strides=(1, 1),\n",
    "    padding='same',\n",
    "    data_format=None,\n",
    "    dilation_rate=(1, 1),\n",
    "    activation=None,\n",
    "    use_bias=True,\n",
    "    kernel_initializer='glorot_uniform',\n",
    "    bias_initializer='zeros',\n",
    "    kernel_regularizer=l2(0.0005),\n",
    "    bias_regularizer=None,\n",
    "    activity_regularizer=None,\n",
    "    kernel_constraint=None,\n",
    "    bias_constraint=None,\n",
    "))\n",
    "# 进行batch normalization\n",
    "model.add(BatchNormalization(\n",
    "    axis=-1,\n",
    "    momentum=0.90,\n",
    "    epsilon=0.001,\n",
    "    center=True,\n",
    "    scale=True,\n",
    "    beta_initializer='zeros',\n",
    "    gamma_initializer='ones',\n",
    "    moving_mean_initializer='zeros',\n",
    "    moving_variance_initializer='ones',\n",
    "    beta_regularizer=None,\n",
    "    gamma_regularizer=None,\n",
    "    beta_constraint=None,\n",
    "    gamma_constraint=None,\n",
    "    renorm=False,\n",
    "    renorm_clipping=None,\n",
    "    renorm_momentum=0.99,\n",
    "    fused=None,\n",
    "    trainable=True,\n",
    "    virtual_batch_size=None,\n",
    "    adjustment=None,\n",
    "    name=None,\n",
    "))\n",
    "model.add(LeakyReLU(\n",
    "    alpha = 0.1\n",
    "))\n",
    "# 第十五层 Convolutional filter 512 size=(3, 3) strides=1, output=14*14\n",
    "model.add(Conv2D(\n",
    "    filters=512,\n",
    "    kernel_size=(3, 3),\n",
    "    strides=(1, 1),\n",
    "    padding='same',\n",
    "    data_format=None,\n",
    "    dilation_rate=(1, 1),\n",
    "    activation=None,\n",
    "    use_bias=True,\n",
    "    kernel_initializer='glorot_uniform',\n",
    "    bias_initializer='zeros',\n",
    "    kernel_regularizer=l2(0.0005),\n",
    "    bias_regularizer=None,\n",
    "    activity_regularizer=None,\n",
    "    kernel_constraint=None,\n",
    "    bias_constraint=None,\n",
    "))\n",
    "# 进行batch normalization\n",
    "model.add(BatchNormalization(\n",
    "    axis=-1,\n",
    "    momentum=0.90,\n",
    "    epsilon=0.001,\n",
    "    center=True,\n",
    "    scale=True,\n",
    "    beta_initializer='zeros',\n",
    "    gamma_initializer='ones',\n",
    "    moving_mean_initializer='zeros',\n",
    "    moving_variance_initializer='ones',\n",
    "    beta_regularizer=None,\n",
    "    gamma_regularizer=None,\n",
    "    beta_constraint=None,\n",
    "    gamma_constraint=None,\n",
    "    renorm=False,\n",
    "    renorm_clipping=None,\n",
    "    renorm_momentum=0.99,\n",
    "    fused=None,\n",
    "    trainable=True,\n",
    "    virtual_batch_size=None,\n",
    "    adjustment=None,\n",
    "    name=None,\n",
    "))\n",
    "model.add(LeakyReLU(\n",
    "    alpha = 0.1\n",
    "))\n",
    "# 第十六层 Convolutional filter 256 size=(1, 1) strides=1, output=14*14\n",
    "model.add(Conv2D(\n",
    "    filters=256,\n",
    "    kernel_size=(1, 1),\n",
    "    strides=(1, 1),\n",
    "    padding='same',\n",
    "    data_format=None,\n",
    "    dilation_rate=(1, 1),\n",
    "    activation=None,\n",
    "    use_bias=True,\n",
    "    kernel_initializer='glorot_uniform',\n",
    "    bias_initializer='zeros',\n",
    "    kernel_regularizer=l2(0.0005),\n",
    "    bias_regularizer=None,\n",
    "    activity_regularizer=None,\n",
    "    kernel_constraint=None,\n",
    "    bias_constraint=None,\n",
    "))\n",
    "# 进行batch normalization\n",
    "model.add(BatchNormalization(\n",
    "    axis=-1,\n",
    "    momentum=0.90,\n",
    "    epsilon=0.001,\n",
    "    center=True,\n",
    "    scale=True,\n",
    "    beta_initializer='zeros',\n",
    "    gamma_initializer='ones',\n",
    "    moving_mean_initializer='zeros',\n",
    "    moving_variance_initializer='ones',\n",
    "    beta_regularizer=None,\n",
    "    gamma_regularizer=None,\n",
    "    beta_constraint=None,\n",
    "    gamma_constraint=None,\n",
    "    renorm=False,\n",
    "    renorm_clipping=None,\n",
    "    renorm_momentum=0.99,\n",
    "    fused=None,\n",
    "    trainable=True,\n",
    "    virtual_batch_size=None,\n",
    "    adjustment=None,\n",
    "    name=None,\n",
    "))\n",
    "model.add(LeakyReLU(\n",
    "    alpha = 0.1\n",
    "))\n",
    "# 第十七层 Convolutional filter 512 size=(3, 3) strides=1, output=14*14\n",
    "model.add(Conv2D(\n",
    "    filters=512,\n",
    "    kernel_size=(3, 3),\n",
    "    strides=(1, 1),\n",
    "    padding='same',\n",
    "    data_format=None,\n",
    "    dilation_rate=(1, 1),\n",
    "    activation=None,\n",
    "    use_bias=True,\n",
    "    kernel_initializer='glorot_uniform',\n",
    "    bias_initializer='zeros',\n",
    "    kernel_regularizer=l2(0.0005),\n",
    "    bias_regularizer=None,\n",
    "    activity_regularizer=None,\n",
    "    kernel_constraint=None,\n",
    "    bias_constraint=None,\n",
    "))\n",
    "# 进行batch normalization\n",
    "model.add(BatchNormalization(\n",
    "    axis=-1,\n",
    "    momentum=0.90,\n",
    "    epsilon=0.001,\n",
    "    center=True,\n",
    "    scale=True,\n",
    "    beta_initializer='zeros',\n",
    "    gamma_initializer='ones',\n",
    "    moving_mean_initializer='zeros',\n",
    "    moving_variance_initializer='ones',\n",
    "    beta_regularizer=None,\n",
    "    gamma_regularizer=None,\n",
    "    beta_constraint=None,\n",
    "    gamma_constraint=None,\n",
    "    renorm=False,\n",
    "    renorm_clipping=None,\n",
    "    renorm_momentum=0.99,\n",
    "    fused=None,\n",
    "    trainable=True,\n",
    "    virtual_batch_size=None,\n",
    "    adjustment=None,\n",
    "    name=None,\n",
    "))\n",
    "model.add(LeakyReLU(\n",
    "    alpha = 0.1\n",
    "))\n",
    "# 第十八层 Maxpool size=(2, 2) strides = 2 outpot 7*7\n",
    "model.add(MaxPool2D(\n",
    "    pool_size=(2, 2),\n",
    "    strides=2,\n",
    "    padding='same',\n",
    "    data_format=None\n",
    "))\n",
    "# 第十九层 Convolutional filter 1024 size=(3, 3) strides=1, output=7*7\n",
    "model.add(Conv2D(\n",
    "    filters=1024,\n",
    "    kernel_size=(3, 3),\n",
    "    strides=(1, 1),\n",
    "    padding='same',\n",
    "    data_format=None,\n",
    "    dilation_rate=(1, 1),\n",
    "    activation=None,\n",
    "    use_bias=True,\n",
    "    kernel_initializer='glorot_uniform',\n",
    "    bias_initializer='zeros',\n",
    "    kernel_regularizer=l2(0.0005),\n",
    "    bias_regularizer=None,\n",
    "    activity_regularizer=None,\n",
    "    kernel_constraint=None,\n",
    "    bias_constraint=None,\n",
    "))\n",
    "# 进行batch normalization\n",
    "model.add(BatchNormalization(\n",
    "    axis=-1,\n",
    "    momentum=0.90,\n",
    "    epsilon=0.001,\n",
    "    center=True,\n",
    "    scale=True,\n",
    "    beta_initializer='zeros',\n",
    "    gamma_initializer='ones',\n",
    "    moving_mean_initializer='zeros',\n",
    "    moving_variance_initializer='ones',\n",
    "    beta_regularizer=None,\n",
    "    gamma_regularizer=None,\n",
    "    beta_constraint=None,\n",
    "    gamma_constraint=None,\n",
    "    renorm=False,\n",
    "    renorm_clipping=None,\n",
    "    renorm_momentum=0.99,\n",
    "    fused=None,\n",
    "    trainable=True,\n",
    "    virtual_batch_size=None,\n",
    "    adjustment=None,\n",
    "    name=None,\n",
    "))\n",
    "model.add(LeakyReLU(\n",
    "    alpha = 0.1\n",
    "))\n",
    "# 第二十层 Convolutional filter 512 size=(1, 1) strides=1, output=7*7\n",
    "model.add(Conv2D(\n",
    "    filters=512,\n",
    "    kernel_size=(1, 1),\n",
    "    strides=(1, 1),\n",
    "    padding='same',\n",
    "    data_format=None,\n",
    "    dilation_rate=(1, 1),\n",
    "    activation=None,\n",
    "    use_bias=True,\n",
    "    kernel_initializer='glorot_uniform',\n",
    "    bias_initializer='zeros',\n",
    "    kernel_regularizer=l2(0.0005),\n",
    "    bias_regularizer=None,\n",
    "    activity_regularizer=None,\n",
    "    kernel_constraint=None,\n",
    "    bias_constraint=None,\n",
    "))\n",
    "# 进行batch normalization\n",
    "model.add(BatchNormalization(\n",
    "    axis=-1,\n",
    "    momentum=0.90,\n",
    "    epsilon=0.001,\n",
    "    center=True,\n",
    "    scale=True,\n",
    "    beta_initializer='zeros',\n",
    "    gamma_initializer='ones',\n",
    "    moving_mean_initializer='zeros',\n",
    "    moving_variance_initializer='ones',\n",
    "    beta_regularizer=None,\n",
    "    gamma_regularizer=None,\n",
    "    beta_constraint=None,\n",
    "    gamma_constraint=None,\n",
    "    renorm=False,\n",
    "    renorm_clipping=None,\n",
    "    renorm_momentum=0.99,\n",
    "    fused=None,\n",
    "    trainable=True,\n",
    "    virtual_batch_size=None,\n",
    "    adjustment=None,\n",
    "    name=None,\n",
    "))\n",
    "model.add(LeakyReLU(\n",
    "    alpha = 0.1\n",
    "))\n",
    "# 第二十一层 Convolutional filter 1024 size=(3, 3) strides=1, output=7*7\n",
    "model.add(Conv2D(\n",
    "    filters=1024,\n",
    "    kernel_size=(3, 3),\n",
    "    strides=(1, 1),\n",
    "    padding='same',\n",
    "    data_format=None,\n",
    "    dilation_rate=(1, 1),\n",
    "    activation=None,\n",
    "    use_bias=True,\n",
    "    kernel_initializer='glorot_uniform',\n",
    "    bias_initializer='zeros',\n",
    "    kernel_regularizer=l2(0.0005),\n",
    "    bias_regularizer=None,\n",
    "    activity_regularizer=None,\n",
    "    kernel_constraint=None,\n",
    "    bias_constraint=None,\n",
    "))\n",
    "# 进行batch normalization\n",
    "model.add(BatchNormalization(\n",
    "    axis=-1,\n",
    "    momentum=0.90,\n",
    "    epsilon=0.001,\n",
    "    center=True,\n",
    "    scale=True,\n",
    "    beta_initializer='zeros',\n",
    "    gamma_initializer='ones',\n",
    "    moving_mean_initializer='zeros',\n",
    "    moving_variance_initializer='ones',\n",
    "    beta_regularizer=None,\n",
    "    gamma_regularizer=None,\n",
    "    beta_constraint=None,\n",
    "    gamma_constraint=None,\n",
    "    renorm=False,\n",
    "    renorm_clipping=None,\n",
    "    renorm_momentum=0.99,\n",
    "    fused=None,\n",
    "    trainable=True,\n",
    "    virtual_batch_size=None,\n",
    "    adjustment=None,\n",
    "    name=None,\n",
    "))\n",
    "model.add(LeakyReLU(\n",
    "    alpha = 0.1\n",
    "))\n",
    "# 第二十二层 Convolutional filter 512 size=(1, 1) strides=1, output=7*7\n",
    "model.add(Conv2D(\n",
    "    filters=512,\n",
    "    kernel_size=(1, 1),\n",
    "    strides=(1, 1),\n",
    "    padding='same',\n",
    "    data_format=None,\n",
    "    dilation_rate=(1, 1),\n",
    "    activation=None,\n",
    "    use_bias=True,\n",
    "    kernel_initializer='glorot_uniform',\n",
    "    bias_initializer='zeros',\n",
    "    kernel_regularizer=l2(0.0005),\n",
    "    bias_regularizer=None,\n",
    "    activity_regularizer=None,\n",
    "    kernel_constraint=None,\n",
    "    bias_constraint=None,\n",
    "))\n",
    "# 进行batch normalization\n",
    "model.add(BatchNormalization(\n",
    "    axis=-1,\n",
    "    momentum=0.90,\n",
    "    epsilon=0.001,\n",
    "    center=True,\n",
    "    scale=True,\n",
    "    beta_initializer='zeros',\n",
    "    gamma_initializer='ones',\n",
    "    moving_mean_initializer='zeros',\n",
    "    moving_variance_initializer='ones',\n",
    "    beta_regularizer=None,\n",
    "    gamma_regularizer=None,\n",
    "    beta_constraint=None,\n",
    "    gamma_constraint=None,\n",
    "    renorm=False,\n",
    "    renorm_clipping=None,\n",
    "    renorm_momentum=0.99,\n",
    "    fused=None,\n",
    "    trainable=True,\n",
    "    virtual_batch_size=None,\n",
    "    adjustment=None,\n",
    "    name=None,\n",
    "))\n",
    "model.add(LeakyReLU(\n",
    "    alpha = 0.1\n",
    "))\n",
    "# 第二十三层 Convolutional filter 1024 size=(3, 3) strides=1, output=7*7\n",
    "model.add(Conv2D(\n",
    "    filters=1024,\n",
    "    kernel_size=(3, 3),\n",
    "    strides=(1, 1),\n",
    "    padding='same',\n",
    "    data_format=None,\n",
    "    dilation_rate=(1, 1),\n",
    "    activation=None,\n",
    "    use_bias=True,\n",
    "    kernel_initializer='glorot_uniform',\n",
    "    bias_initializer='zeros',\n",
    "    kernel_regularizer=l2(0.0005),\n",
    "    bias_regularizer=None,\n",
    "    activity_regularizer=None,\n",
    "    kernel_constraint=None,\n",
    "    bias_constraint=None,\n",
    "))\n",
    "# 进行batch normalization\n",
    "model.add(BatchNormalization(\n",
    "    axis=-1,\n",
    "    momentum=0.90,\n",
    "    epsilon=0.001,\n",
    "    center=True,\n",
    "    scale=True,\n",
    "    beta_initializer='zeros',\n",
    "    gamma_initializer='ones',\n",
    "    moving_mean_initializer='zeros',\n",
    "    moving_variance_initializer='ones',\n",
    "    beta_regularizer=None,\n",
    "    gamma_regularizer=None,\n",
    "    beta_constraint=None,\n",
    "    gamma_constraint=None,\n",
    "    renorm=False,\n",
    "    renorm_clipping=None,\n",
    "    renorm_momentum=0.99,\n",
    "    fused=None,\n",
    "    trainable=True,\n",
    "    virtual_batch_size=None,\n",
    "    adjustment=None,\n",
    "    name=None,\n",
    "))\n",
    "model.add(LeakyReLU(\n",
    "    alpha = 0.1\n",
    "))\n",
    "# 第二十四层 Convolutional filter 1024 size=(3, 3) strides=1, output=7*7\n",
    "model.add(Conv2D(\n",
    "    filters=1000,\n",
    "    kernel_size=(1, 1),\n",
    "    strides=(1, 1),\n",
    "    padding='same',\n",
    "    data_format=None,\n",
    "    dilation_rate=(1, 1),\n",
    "    activation=None,\n",
    "    use_bias=True,\n",
    "    kernel_initializer='glorot_uniform',\n",
    "    bias_initializer='zeros',\n",
    "    kernel_regularizer=l2(0.0005),\n",
    "    bias_regularizer=None,\n",
    "    activity_regularizer=None,\n",
    "    kernel_constraint=None,\n",
    "    bias_constraint=None,\n",
    "))\n",
    "# 进行batch normalization\n",
    "model.add(BatchNormalization(\n",
    "    axis=-1,\n",
    "    momentum=0.90,\n",
    "    epsilon=0.001,\n",
    "    center=True,\n",
    "    scale=True,\n",
    "    beta_initializer='zeros',\n",
    "    gamma_initializer='ones',\n",
    "    moving_mean_initializer='zeros',\n",
    "    moving_variance_initializer='ones',\n",
    "    beta_regularizer=None,\n",
    "    gamma_regularizer=None,\n",
    "    beta_constraint=None,\n",
    "    gamma_constraint=None,\n",
    "    renorm=False,\n",
    "    renorm_clipping=None,\n",
    "    renorm_momentum=0.99,\n",
    "    fused=None,\n",
    "    trainable=True,\n",
    "    virtual_batch_size=None,\n",
    "    adjustment=None,\n",
    "    name=None,\n",
    "))\n",
    "model.add(LeakyReLU(\n",
    "    alpha = 0.1\n",
    "))\n",
    "model.add(GlobalAveragePooling2D())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'NoneType'>, <class 'NoneType'>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Please provide as model inputs either a single array or a list of arrays. You passed: inputs=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-db6cf083edba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     19\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'yolo_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m         shuffle=shuffle)\n\u001b[0m\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2417\u001b[0m     \u001b[0;31m# First, we build the model on the fly if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2419\u001b[0;31m       \u001b[0mall_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_model_with_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2420\u001b[0m       \u001b[0mis_build_called\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2421\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_build_model_with_inputs\u001b[0;34m(self, inputs, targets)\u001b[0m\n\u001b[1;32m   2580\u001b[0m     \u001b[0;31m# or lists of arrays, and extract a flat list of inputs from the passed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2581\u001b[0m     \u001b[0;31m# structure.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2582\u001b[0;31m     \u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_input_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2584\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mvalidate_input_types\u001b[0;34m(inp, orig_inp, allow_dict, field_name)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     raise ValueError(\n\u001b[1;32m   1150\u001b[0m         \u001b[0;34m'Please provide as model inputs either a single array or a list of '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         'arrays. You passed: {}={}'.format(field_name, orig_inp))\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Please provide as model inputs either a single array or a list of arrays. You passed: inputs=None"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow import placeholder\n",
    "model.compile(\n",
    "    optimizer=SGD(0.000001),\n",
    ")\n",
    "# 需要传入图片\n",
    "X = None # 没有获取具体数据\n",
    "y = None\n",
    "model.fit(\n",
    "    x=X,\n",
    "    y=y,\n",
    "    batch_size=32,\n",
    "    epochs=10,\n",
    "    verbose=1,\n",
    "    validation_split=0.0,\n",
    "    initial_epoch=10,\n",
    "    steps_per_epoch=1,\n",
    ")\n",
    "model.save('yolo_model.h5')\n",
    "# 文中最后作者使用了wordtree 此处没有进行下一步数据集的训练 # 原因 2015款：macbook pro 跑不动"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog.jpg      model.ipynb  model.py\r\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}